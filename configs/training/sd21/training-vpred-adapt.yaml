
image_finetune: false

output_dir: "outputs-sd2-vpredadapt-6000resumecos"
#pretrained_model_path: "/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/1d0c4ebf6ff58a5caecab40fa1406526bca4b5b9/"
pretrained_model_path: "/root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1/snapshots/5cae40e6a2745ae2b01ad92ae5043f95f23644d6/"

# resume from sd1.5 ckpt, adapt to v-pred takes relatively few steps
#resume_ckpt: "models/Motion_Module/v3_sd15_mm.ckpt"
resume_ckpt: "outputs-sd2-vpredadapt/checkpoint-6000.ckpt"

unet_additional_kwargs:
  use_motion_module              : true
  motion_module_resolutions      : [ 1,2,4,8 ]
  unet_use_cross_frame_attention : false
  unet_use_temporal_attention    : false

  motion_module_decoder_only:     false

  # v1:
  # use_inflated_groupnorm: false
  # motion_module_mid_block: false

  # v2:
  # use_inflated_groupnorm: true
  # motion_module_mid_block: true

  # v3:
  # use_inflated_groupnorm:     true
  # motion_module_mid_block: false

  use_inflated_groupnorm:     true
  motion_module_mid_block: false

  motion_module_type: Vanilla
  motion_module_kwargs:
    num_attention_heads                : 8
    num_transformer_block              : 1
    attention_block_types              : [ "Temporal_Self", "Temporal_Self" ]
    temporal_position_encoding         : true
    # v1:
    # temporal_position_encoding_max_len : 24
    # v2, v3:
    # temporal_position_encoding_max_len: 32
    temporal_position_encoding_max_len: 32
    temporal_attention_dim_div         : 1
    zero_initialize                    : true




noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

train_data:
  # random sample of 4058 entries from webvid-2M-val
  csv_path:        "/workspace/webvid/results_2M_val-4058.csv"
  video_folder:    "/workspace/webvid/2M_val"
  sample_size:     256
  sample_stride:   4
  sample_n_frames: 16

validation_data:
  prompts:
    - "Snow rocky mountains peaks canyon. Snow blanketed rocky mountains surround and shadow deep canyons."
    - "A drone view of celebration with Christma tree and fireworks, starry sky - background."
    - "Robot dancing in times square."
    - "Pacific coast, carmel by the sea ocean and waves."
  num_inference_steps: 25
  guidance_scale: 8.

trainable_modules:
  - "motion_modules."

unet_checkpoint_path: ""

learning_rate:    1.e-4
train_batch_size: 1
gradient_accumulation_steps: 4
lr_warmup_steps: 1
lr_scheduler: "cosine"

max_train_epoch:      -1
max_train_steps:      10000
checkpointing_epochs: -1
checkpointing_steps:  1000

validation_steps:       1000
validation_steps_tuple: [4, 50]

global_seed: -1
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: False
use_adamw8bit: True
